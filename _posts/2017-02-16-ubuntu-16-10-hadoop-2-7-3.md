---
layout: post
title:  "우분투 16.10 - hadoop 2.7.3 설치"
categories: hadoop 하둡
date:   2017-02-15 14:00
permalink: /archivers/ubuntu16-10-hadoop-2-7-3
---

# 서버 구성

| 구분           |             IP   |  host name  |
|----------------|------------------|-------------|
| name node      | 192.168.10.123   |  master     |
| data node      | 192.168.10.124   |  data01     |
| data node      | 192.168.10.175   |  data02     |
| data node      | 192.168.10.60    |  data03     |


# 서버 준비

## 환경 설정

- 대상 : 모든 서버

```bash
choochangho@master:~$ sudo apt-get update
choochangho@master:~$ sudo apt-get upgrade
```

## 자바설치

- 대상 : 모든 서버

```bash
choochangho@master:~$ sudo apt purge openjdk*
choochangho@master:~$ sudo add-apt-repository -y ppa:webupd8team/java
choochangho@master:~$ sudo apt update
choochangho@master:~$ sudo apt install -y oracle-java8-installer
```

설치 완료 후 버전 확인 및 환경 변수 추가

```bash
choochangho@master:~$ java -version
java version "1.8.0_66"
...

choochangho@master:~$ sudo sh -c 'echo "export JAVA_HOME=/usr" >> /etc/profile'
choochangho@master:~$ source /etc/profile
```

## 호스트 파일 수정

- 대상 : 모든 서버
- /etc/hosts

```text
127.0.0.1       localhost
#127.0.1.1      master

# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

192.168.10.123  master
192.168.10.124  data01
192.168.10.175  data02
192.168.10.60   data03
```

127.0.1.1 라인은 주석 처리

## IPV6 

- 대상 : 모든 서버
- /etc/sysctl.conf

```text
# disable ipv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
```

수정 후 서버 Reboot

## 하둡 그룹 및 계정 추가

- 대상 : 모든 서버

```bash
choochangho@master:~$ sudo addgroup hadoop
choochangho@master:~$ sudo adduser --ingroup hadoop hadoop-user
``` 

## ssh 암호 없이 로그인 가능하도록 설정

- 대상 : master

```bash
hadoop-user@master:~$ ssh-keygen -t rsa -P ""
hadoop-user@master:~$ cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
hadoop-user@master:~$ ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop-user@data01
hadoop-user@master:~$ ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop-user@data02
hadoop-user@master:~$ ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop-user@data03

# Try Login
hadoop-user@master:~$ ssh master
hadoop-user@master:~$ ssh data01
hadoop-user@master:~$ ssh data02
hadoop-user@master:~$ ssh data03

``` 

## Data Node 의 hadoop 데이터 디렉토리 권한 설정

- 대상 : data01, data02, data03 (디렉토리를 6개 가정)

```bash
choochangho@data0x:~$ sudo mkdir /data01/datanode
choochangho@data0x:~$ sudo mkdir /data02/datanode
choochangho@data0x:~$ sudo mkdir /data03/datanode
choochangho@data0x:~$ sudo mkdir /data04/datanode
choochangho@data0x:~$ sudo mkdir /data05/datanode
choochangho@data0x:~$ sudo mkdir /data06/datanode

choochangho@data0x:~$ sudo chown -R hadoop-user:hadoop /data01
choochangho@data0x:~$ sudo chown -R hadoop-user:hadoop /data02
choochangho@data0x:~$ sudo chown -R hadoop-user:hadoop /data03
choochangho@data0x:~$ sudo chown -R hadoop-user:hadoop /data04
choochangho@data0x:~$ sudo chown -R hadoop-user:hadoop /data05
choochangho@data0x:~$ sudo chown -R hadoop-user:hadoop /data06
```

# 하둡

## 다운로드

- 대상 : master

```bash
choochangho@master:~$ wget http://mirror.navercorp.com/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
choochangho@master:~$ tar xzf hadoop-2.7.3.tar.gz
choochangho@master:~$ rm hadoop-2.7.3.tar.gz
choochangho@master:~$ sudo mv hadoop-2.7.3 /usr/local
choochangho@master:~$ sudo ln -sf /usr/local/hadoop-2.7.3/ /usr/local/hadoop
choochangho@master:~$ sudo chown -R hadoop-user:hadoop /usr/localhadoop-2.7.3/
```

## hadoop-user의 환경 설정

- 대상 : 모든 서버
- /home/hadoop-user/.bashrc

```bash
choochangho@master:~$ su - hadoop-user
...
...
hadoop-user@master:~$ vi ~/.bashrc

# Set Hadoop-related environment variables
export HADOOP_PREFIX=/usr/local/hadoop
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
# Native path
export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_PREFIX}/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_PREFIX/lib/native"
# Java path
export JAVA_HOME="/usr"
# Add Hadoop bin/ directory to PATH
export PATH=$PATH:$HADOOP_HOME/bin:$JAVA_PATH/bin:$HADOOP_HOME/sbin


hadoop-user@master:~$ source ~/.bashrc
```

## 하둡 설정

- 대상 : master
- /usr/local/hadoop/etc/hadoop/{설정파일}

### yarn-site.xml

```xml
<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>

<!-- Site specific YARN configuration properties -->
<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>

<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>master</value>
</property>

<property>
	<name>yarn.resourcemanager.address</name>
	<value>master:8032</value>
</property>

</configuration>
```

### core-site.xml

```xml
<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>

<!-- Site specific YARN configuration properties -->
<property>
	<name>fs.defaultFS</name>
	<value>hdfs://master:9000</value>
</property>

</configuration>
```

### mapred-site.xml ( cp mapred-site.xml.template mapred-site.xml )

```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>

</configuration>
```

### hdfs-site.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>
	<name>dfs.replication</name>
	<value>3</value>
</property>
<property>
	<name>dfs.namenode.name.dir</name>
	<value>/usr/local/hadoop/yarn_data/hdfs/namenode</value>
</property>
<property>
	<name>dfs.datanode.data.dir</name>
	<value>/data01/datanode,/data02/datanode,/data03/datanode,/data04/datanode,/data05/datanode,/data06/datanode</value>
</property>

</configuration>
```

### name node 디렉토리 생성

- 대상 : master

```
hadoop-user@master:~$ mkdir -p /usr/local/hadoop/yarn_data/hdfs/namenode
```

### 배포

- 대상 : master
- /usr/local/hadoop 디렉토리를 data01, data02, data03 서버로 복사
- 이후 설정 파일만 별도로 배포한다.


## hdfs 포맷

- 대상 : master

```bash
hadoop-user@master:~$ hdfs namenode -format
```

## 하둡 실행

```bash
hadoop-user@master:~$ cd /usr/local/hadoop/sbin
hadoop-user@master:~$ ./start-all.sh

# 또는

hadoop-user@master:~$ start-dfs.sh
hadoop-user@master:~$ start-yarn.sh
```

리소스 매니저가 뜨지 않는다면..

```bash
hadoop-user@master:~$ ./yarn-daemon.sh start nodemanager
hadoop-user@master:~$ ./yarn-daemon.sh start resourcemanager

# 또는

hadoop-user@master:~$ start-dfs.sh
hadoop-user@master:~$ start-yarn.sh
```



## 하둡 테스트

```bash
hadoop-user@master:~$ hdfs dfs -mkdir /user
hadoop-user@master:~$ hdfs dfs -mkdir /user/hadoop-user
hadoop-user@master:~$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar pi 10 1000
Number of Maps  = 10
Samples per Map = 1000
Wrote input for Map #0
Wrote input for Map #1
Wrote input for Map #2
Wrote input for Map #3
Wrote input for Map #4
Wrote input for Map #5
Wrote input for Map #6
Wrote input for Map #7
Wrote input for Map #8
Wrote input for Map #9
Starting Job
17/02/16 15:25:41 INFO client.RMProxy: Connecting to ResourceManager at master/192.168.10.123:8032
17/02/16 15:25:41 INFO input.FileInputFormat: Total input paths to process : 10
17/02/16 15:25:42 INFO mapreduce.JobSubmitter: number of splits:10
17/02/16 15:25:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1487225280948_0003
17/02/16 15:25:42 INFO impl.YarnClientImpl: Submitted application application_1487225280948_0003
17/02/16 15:25:42 INFO mapreduce.Job: The url to track the job: http://master:8088/proxy/application_1487225280948_0003/
17/02/16 15:25:42 INFO mapreduce.Job: Running job: job_1487225280948_0003
17/02/16 15:25:49 INFO mapreduce.Job: Job job_1487225280948_0003 running in uber mode : false
17/02/16 15:25:49 INFO mapreduce.Job:  map 0% reduce 0%
17/02/16 15:25:55 INFO mapreduce.Job:  map 20% reduce 0%
17/02/16 15:25:56 INFO mapreduce.Job:  map 30% reduce 0%
17/02/16 15:25:57 INFO mapreduce.Job:  map 40% reduce 0%
17/02/16 15:25:58 INFO mapreduce.Job:  map 50% reduce 0%
17/02/16 15:25:59 INFO mapreduce.Job:  map 60% reduce 0%
17/02/16 15:26:00 INFO mapreduce.Job:  map 70% reduce 0%
17/02/16 15:26:01 INFO mapreduce.Job:  map 80% reduce 0%
17/02/16 15:26:02 INFO mapreduce.Job:  map 100% reduce 0%
17/02/16 15:26:03 INFO mapreduce.Job:  map 100% reduce 100%
17/02/16 15:26:03 INFO mapreduce.Job: Job job_1487225280948_0003 completed successfully
17/02/16 15:26:03 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=226
                FILE: Number of bytes written=1310078
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=2670
                HDFS: Number of bytes written=215
                HDFS: Number of read operations=43
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=3
        Job Counters 
                Launched map tasks=10
                Launched reduce tasks=1
                Rack-local map tasks=10
                Total time spent by all maps in occupied slots (ms)=27181
                Total time spent by all reduces in occupied slots (ms)=5156
                Total time spent by all map tasks (ms)=27181
                Total time spent by all reduce tasks (ms)=5156
                Total vcore-milliseconds taken by all map tasks=27181
                Total vcore-milliseconds taken by all reduce tasks=5156
                Total megabyte-milliseconds taken by all map tasks=27833344
                Total megabyte-milliseconds taken by all reduce tasks=5279744
        Map-Reduce Framework
                Map input records=10
                Map output records=20
                Map output bytes=180
                Map output materialized bytes=280
                Input split bytes=1490
                Combine input records=0
                Combine output records=0
                Reduce input groups=2
                Reduce shuffle bytes=280
                Reduce input records=20
                Reduce output records=0
                Spilled Records=40
                Shuffled Maps =10
                Failed Shuffles=0
                Merged Map outputs=10
                GC time elapsed (ms)=813
                CPU time spent (ms)=7100
                Physical memory (bytes) snapshot=3043205120
                Virtual memory (bytes) snapshot=21818175488
                Total committed heap usage (bytes)=2159542272
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=1180
        File Output Format Counters 
                Bytes Written=97
Job Finished in 22.508 seconds
Estimated value of Pi is 3.14080000000000000000
```

## 하둡 web ui

- http://\<name-node ip\>:50070